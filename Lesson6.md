# Deep Learning
## Lesson 6


<h3>What are Activation Functions in a neural network?</h3>
Activation functions are used to determine(or activate) the output of neural network depending upon the input values. This function decides whether a neuron should be activated or not.

<h4>Types of Activation Function<h4>
  
  * <strong>Sigmoid Activation Function</strong> <br>
The ouput value ranges from 0 to 1. The function can be used to predict the probability however it is usually not used in recent times as it suffers from vanishing gradient problem. 
  <p align="center">
  <br>
  <img src="https://user-images.githubusercontent.com/45029614/163190412-bc118475-2107-43c6-9cb3-7a0534a31693.PNG" width="750" title="CNN">
</p>

* <strong>Hyperbolic tangent Activation Function</strong> 
The hyperbolic tangent performs a little bit better than the sigmoid function. The output of the hyperbolic tangent lies between -1 to 1. However, this function also suffers from vanishing gradient problem.
  
   <p align="center">
  <br>
  <img src="https://user-images.githubusercontent.com/45029614/163191593-ff8826d7-1b04-4ce4-abb6-d5fdd284c41e.PNG" width="750" title="CNN">
</p>


  
  
  
